hydra:
  run:
    dir: ${cache_path}/${task}/${model}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: llama3-8b
  - estimators: single_sequence_estimators
  - stat_calculators: default_calculators
  - base_processing_mmlu_reasoning
  - _self_


cache_path: ./workdir/output
save_path: '${hydra:run.dir}'
instruct: false
task: qa

dataset: ['denis1699/mmlu_reasoning']
text_column: question
label_column: answer
train_split: train
eval_split: test
few_shot_prompt: null
max_new_tokens: 512
load_from_disk: false
trust_remote_code: false


subsample_eval_dataset: 1000

generation_metrics: null

generation_params:
  generate_until:
    - "Q:"
    - "Question:"
    - "\n\n"

ignore_exceptions: false

batch_size: 1

stat_calculator:
    batch_size: 1

seed:
    - 1
